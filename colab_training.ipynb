{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperspectral Material Classification - Google Colab Training\n",
    "\n",
    "This notebook trains the material classification model on Google Colab's free GPU.\n",
    "\n",
    "**Before running:**\n",
    "1. Runtime → Change runtime type → GPU (T4)\n",
    "2. Upload your data to Google Drive\n",
    "3. Run cells in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/PlugNawapong/my-ml-project.git\n",
    "%cd my-ml-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision albumentations tqdm Pillow numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data from Google Drive to Colab workspace\n",
    "# ADJUST THE PATH to match your Google Drive folder structure\n",
    "\n",
    "import os\n",
    "\n",
    "# Example path - adjust to your Google Drive structure\n",
    "drive_data_path = '/content/drive/MyDrive/dl-plastics-data'\n",
    "\n",
    "# Copy training data\n",
    "if os.path.exists(f'{drive_data_path}/data'):\n",
    "    !cp -r {drive_data_path}/data ./\n",
    "    print('✓ Training data copied')\n",
    "else:\n",
    "    print('⚠ Training data not found. Please upload to Google Drive first.')\n",
    "\n",
    "# Copy inference datasets\n",
    "if os.path.exists(f'{drive_data_path}/inference_data_set1'):\n",
    "    !cp -r {drive_data_path}/inference_data_set1 ./\n",
    "    print('✓ Inference dataset 1 copied')\n",
    "\n",
    "if os.path.exists(f'{drive_data_path}/inference_data_set2'):\n",
    "    !cp -r {drive_data_path}/inference_data_set2 ./\n",
    "    print('✓ Inference dataset 2 copied')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect training data\n",
    "!python inspect_data.py --data_dir data\n",
    "\n",
    "# Display generated plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print('\\n=== Band Visualization ===')\n",
    "display(Image('data_inspection_bands.png'))\n",
    "\n",
    "print('\\n=== Label Visualization ===')\n",
    "display(Image('data_inspection_labels.png'))\n",
    "\n",
    "print('\\n=== Raw Spectral Signatures ===')\n",
    "display(Image('data_inspection_spectra_raw.png'))\n",
    "\n",
    "print('\\n=== Normalized Spectral Signatures (Used in Training) ===')\n",
    "display(Image('data_inspection_spectra_normalized.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model\n",
    "\n",
    "Choose one of the training options below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Fast 1D Model (Recommended for Quick Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "    --model spectral_cnn_1d \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 2048 \\\n",
    "    --max_samples_per_class 10000 \\\n",
    "    --dropout 0.5 \\\n",
    "    --lr 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: 2D CNN with Spatial Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "    --model spectral_cnn_2d \\\n",
    "    --use_patches \\\n",
    "    --patch_size 3 \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 512 \\\n",
    "    --max_samples_per_class 5000 \\\n",
    "    --dropout 0.5 \\\n",
    "    --bin_factor 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Hybrid Model (Best Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "    --model hybrid \\\n",
    "    --use_patches \\\n",
    "    --patch_size 5 \\\n",
    "    --epochs 100 \\\n",
    "    --batch_size 256 \\\n",
    "    --max_samples_per_class 5000 \\\n",
    "    --dropout 0.5 \\\n",
    "    --augment \\\n",
    "    --bin_factor 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest trained model\n",
    "import glob\n",
    "model_files = glob.glob('outputs/*/best_model.pth')\n",
    "if model_files:\n",
    "    latest_model = sorted(model_files)[-1]\n",
    "    print(f'Using model: {latest_model}')\n",
    "else:\n",
    "    print('No trained model found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on inference_data_set1\n",
    "!python inference.py \\\n",
    "    --checkpoint {latest_model} \\\n",
    "    --model spectral_cnn_1d \\\n",
    "    --data_dir inference_data_set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on inference_data_set2\n",
    "!python inference.py \\\n",
    "    --checkpoint {latest_model} \\\n",
    "    --model spectral_cnn_1d \\\n",
    "    --data_dir inference_data_set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display prediction visualizations\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "print('\\n=== Inference Data Set 1 Results ===')\n",
    "display(Image('predictions/inference_data_set1/prediction_visualization.png'))\n",
    "\n",
    "# Show statistics\n",
    "with open('predictions/inference_data_set1/statistics.json', 'r') as f:\n",
    "    stats1 = json.load(f)\n",
    "print(f\"Mean Confidence: {stats1['mean_confidence']:.4f}\")\n",
    "print(\"\\nClass Distribution:\")\n",
    "for class_name, class_stats in stats1['class_distribution'].items():\n",
    "    if class_stats['percentage'] > 0:\n",
    "        print(f\"  {class_name}: {class_stats['percentage']:.2f}% (conf: {class_stats['mean_confidence']:.4f})\")\n",
    "\n",
    "print('\\n=== Inference Data Set 2 Results ===')\n",
    "display(Image('predictions/inference_data_set2/prediction_visualization.png'))\n",
    "\n",
    "with open('predictions/inference_data_set2/statistics.json', 'r') as f:\n",
    "    stats2 = json.load(f)\n",
    "print(f\"Mean Confidence: {stats2['mean_confidence']:.4f}\")\n",
    "print(\"\\nClass Distribution:\")\n",
    "for class_name, class_stats in stats2['class_distribution'].items():\n",
    "    if class_stats['percentage'] > 0:\n",
    "        print(f\"  {class_name}: {class_stats['percentage']:.2f}% (conf: {class_stats['mean_confidence']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip all results\n",
    "!zip -r results.zip outputs/ predictions/\n",
    "\n",
    "# Download to your computer\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n",
    "\n",
    "print('\\n✓ Results downloaded! Extract the zip file to see:')\n",
    "print('  - outputs/ : Trained models and training history')\n",
    "print('  - predictions/ : Inference results and visualizations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results back to Google Drive\n",
    "!mkdir -p /content/drive/MyDrive/dl-plastics-results\n",
    "!cp -r outputs/ /content/drive/MyDrive/dl-plastics-results/\n",
    "!cp -r predictions/ /content/drive/MyDrive/dl-plastics-results/\n",
    "\n",
    "print('✓ Results saved to Google Drive: /MyDrive/dl-plastics-results/')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
